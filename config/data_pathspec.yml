text_difficulty:
    raw: "../OneStopEnglishCorpus/Texts-Together-OneCSVPerFile"
    post: "./data/osec.csv"
emotions:
    raw: "../GoEmotions/" # points to a directory w/ the same structure as https://github.com/google-research/google-research/tree/master/goemotions/data
    post: "./data/goemotions.csv"
wcep:
    raw: "../../wcp-mds-dataset/val.jsonl/val.jsonl"
    post: "./data/wcep.csv"
steerbench_t2t:
    raw:
        - name: "ccdv/cnn_dailymail"
          hf: True
          split: "validation"
          feature_col: "article"
          kwargs:
              version: "3.0.0"
        - name: "kmfoda/booksum"
          hf: True
          split: "validation"
          feature_col: "chapter"
          kwargs:
              paragraph_chunksize: 30
              sample: 300 
              random_state: 42
              filters:
                  source: "sparknotes" # why? there are duped chapters (diff. sources cover same books); sparknotes is chapter-by-chapter
        - name: "ctr4si/reddit_tifu"
          hf: True
          split: "train"
          feature_col: "documents"
          kwargs: 
              version: "short" # the only diff. here is the summary type (title vs. TL;DR -- doesn't matter for us)
              newlines_are_sentences: True
              sample: 3000
              random_state: 42
        - name: "tau/scrolls"
          hf: True
          split: "validation"
          feature_col: "output" # could switch to input if we want to rewrite scripts
          kwargs:
              version: "summ_screen_fd"
    post: "./data/steerbench_t2t_v3.csv"
_int_booksum: # for easy access to intermediate sub-datasets, if needed
    post: "./data/_intermediate_booksum.csv"
_int_cnndm:
    post: "./data/_intermediate_cnn_dailymail.csv"
_int_tifu:
    post: "./data/_intermediate_reddit_tifu.csv"
_int_scrolls:
    post: "./data/_intermediate_scrolls.csv"