INFO 05-07 02:15:32 [__init__.py:239] Automatically detected platform cuda.
INFO 05-07 02:15:35 [api_server.py:1034] vLLM API server version 0.8.4
INFO 05-07 02:15:35 [api_server.py:1035] args: Namespace(subparser='serve', model_tag='meta-llama/Llama-3.1-8B-Instruct', config='', host=None, port=16385, uvicorn_log_level='info', disable_uvicorn_access_log=False, allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, lora_modules=None, prompt_adapters=None, chat_template=None, chat_template_content_format='auto', response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, enable_ssl_refresh=False, ssl_cert_reqs=0, root_path=None, middleware=[], return_tokens_as_token_ids=False, disable_frontend_multiprocessing=False, enable_request_id_headers=False, enable_auto_tool_choice=False, tool_call_parser=None, tool_parser_plugin='', model='meta-llama/Llama-3.1-8B-Instruct', task='auto', tokenizer=None, hf_config_path=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, allowed_local_media_path=None, load_format='auto', download_dir=None, model_loader_extra_config=None, use_tqdm_on_load=True, config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', max_model_len=32000, guided_decoding_backend='auto', logits_processor_pattern=None, model_impl='auto', distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=1, data_parallel_size=1, enable_expert_parallel=False, max_parallel_loading_workers=None, ray_workers_use_nsight=False, disable_custom_all_reduce=False, block_size=None, enable_prefix_caching=None, prefix_caching_hash_algo='builtin', disable_sliding_window=False, use_v2_block_manager=True, num_lookahead_slots=0, seed=None, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.8, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_partial_prefills=1, max_long_partial_prefills=1, long_prefill_token_threshold=0, max_num_seqs=None, max_logprobs=20, disable_log_stats=False, quantization=None, rope_scaling=None, rope_theta=None, hf_token=None, hf_overrides=None, enforce_eager=False, max_seq_len_to_capture=8192, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, mm_processor_kwargs=None, disable_mm_preprocessor_cache=False, enable_lora=False, enable_lora_bias=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', long_lora_scaling_factors=None, max_cpu_loras=None, fully_sharded_loras=False, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, scheduler_delay_factor=0.0, enable_chunked_prefill=None, speculative_config=None, ignore_patterns=[], preemption_mode=None, served_model_name=None, qlora_adapter_name_or_path=None, show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, scheduling_policy='fcfs', scheduler_cls='vllm.core.scheduler.Scheduler', override_neuron_config=None, override_pooler_config=None, compilation_config=None, kv_transfer_config=None, worker_cls='auto', worker_extension_cls='', generation_config='auto', override_generation_config=None, enable_sleep_mode=False, calculate_kv_scales=False, additional_config=None, enable_reasoning=False, reasoning_parser=None, disable_cascade_attn=False, disable_chunked_mm_input=False, disable_log_requests=False, max_log_len=None, disable_fastapi_docs=False, enable_prompt_tokens_details=False, enable_server_load_tracking=False, dispatch_function=<function ServeSubcommand.cmd at 0x7febd24cfb00>)
INFO 05-07 02:15:46 [config.py:689] This model supports multiple tasks: {'score', 'generate', 'reward', 'classify', 'embed'}. Defaulting to 'generate'.
INFO 05-07 02:15:46 [config.py:1901] Chunked prefill is enabled with max_num_batched_tokens=2048.
INFO 05-07 02:15:51 [__init__.py:239] Automatically detected platform cuda.
INFO 05-07 02:15:56 [core.py:61] Initializing a V1 LLM engine (v0.8.4) with config: model='meta-llama/Llama-3.1-8B-Instruct', speculative_config=None, tokenizer='meta-llama/Llama-3.1-8B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=None, served_model_name=meta-llama/Llama-3.1-8B-Instruct, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={"level":3,"custom_ops":["none"],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output"],"use_inductor":true,"compile_sizes":[],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"max_capture_size":512}
WARNING 05-07 02:15:56 [utils.py:2444] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x7f37b58081d0>
INFO 05-07 02:15:57 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0
INFO 05-07 02:15:57 [cuda.py:221] Using Flash Attention backend on V1 engine.
INFO 05-07 02:15:57 [gpu_model_runner.py:1276] Starting to load model meta-llama/Llama-3.1-8B-Instruct...
ERROR 05-07 02:15:58 [core.py:387] EngineCore hit an exception: Traceback (most recent call last):
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 378, in run_engine_core
ERROR 05-07 02:15:58 [core.py:387]     engine_core = EngineCoreProc(*args, **kwargs)
ERROR 05-07 02:15:58 [core.py:387]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 320, in __init__
ERROR 05-07 02:15:58 [core.py:387]     super().__init__(vllm_config, executor_class, log_stats)
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 67, in __init__
ERROR 05-07 02:15:58 [core.py:387]     self.model_executor = executor_class(vllm_config)
ERROR 05-07 02:15:58 [core.py:387]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/executor/executor_base.py", line 52, in __init__
ERROR 05-07 02:15:58 [core.py:387]     self._init_executor()
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 47, in _init_executor
ERROR 05-07 02:15:58 [core.py:387]     self.collective_rpc("load_model")
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
ERROR 05-07 02:15:58 [core.py:387]     answer = run_method(self.driver_worker, method, args, kwargs)
ERROR 05-07 02:15:58 [core.py:387]              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/utils.py", line 2378, in run_method
ERROR 05-07 02:15:58 [core.py:387]     return func(*args, **kwargs)
ERROR 05-07 02:15:58 [core.py:387]            ^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 136, in load_model
ERROR 05-07 02:15:58 [core.py:387]     self.model_runner.load_model()
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/v1/worker/gpu_model_runner.py", line 1279, in load_model
ERROR 05-07 02:15:58 [core.py:387]     self.model = get_model(vllm_config=self.vllm_config)
ERROR 05-07 02:15:58 [core.py:387]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/model_loader/__init__.py", line 14, in get_model
ERROR 05-07 02:15:58 [core.py:387]     return loader.load_model(vllm_config=vllm_config)
ERROR 05-07 02:15:58 [core.py:387]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/model_loader/loader.py", line 452, in load_model
ERROR 05-07 02:15:58 [core.py:387]     model = _initialize_model(vllm_config=vllm_config)
ERROR 05-07 02:15:58 [core.py:387]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/model_loader/loader.py", line 133, in _initialize_model
ERROR 05-07 02:15:58 [core.py:387]     return model_class(vllm_config=vllm_config, prefix=prefix)
ERROR 05-07 02:15:58 [core.py:387]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 486, in __init__
ERROR 05-07 02:15:58 [core.py:387]     self.model = self._init_model(vllm_config=vllm_config,
ERROR 05-07 02:15:58 [core.py:387]                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 527, in _init_model
ERROR 05-07 02:15:58 [core.py:387]     return LlamaModel(vllm_config=vllm_config,
ERROR 05-07 02:15:58 [core.py:387]            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/compilation/decorators.py", line 151, in __init__
ERROR 05-07 02:15:58 [core.py:387]     old_init(self, vllm_config=vllm_config, prefix=prefix, **kwargs)
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 321, in __init__
ERROR 05-07 02:15:58 [core.py:387]     self.start_layer, self.end_layer, self.layers = make_layers(
ERROR 05-07 02:15:58 [core.py:387]                                                     ^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/models/utils.py", line 610, in make_layers
ERROR 05-07 02:15:58 [core.py:387]     maybe_offload_to_cpu(layer_fn(prefix=f"{prefix}.{idx}"))
ERROR 05-07 02:15:58 [core.py:387]                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 323, in <lambda>
ERROR 05-07 02:15:58 [core.py:387]     lambda prefix: layer_type(config=config,
ERROR 05-07 02:15:58 [core.py:387]                    ^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 254, in __init__
ERROR 05-07 02:15:58 [core.py:387]     self.mlp = LlamaMLP(
ERROR 05-07 02:15:58 [core.py:387]                ^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/models/llama.py", line 78, in __init__
ERROR 05-07 02:15:58 [core.py:387]     self.down_proj = RowParallelLinear(
ERROR 05-07 02:15:58 [core.py:387]                      ^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 1169, in __init__
ERROR 05-07 02:15:58 [core.py:387]     self.quant_method.create_weights(
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/vllm/model_executor/layers/linear.py", line 178, in create_weights
ERROR 05-07 02:15:58 [core.py:387]     weight = Parameter(torch.empty(sum(output_partition_sizes),
ERROR 05-07 02:15:58 [core.py:387]                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387]   File "/data2/ctrenton/uv/llm_server/lib/python3.12/site-packages/torch/utils/_device.py", line 104, in __torch_function__
ERROR 05-07 02:15:58 [core.py:387]     return func(*args, **kwargs)
ERROR 05-07 02:15:58 [core.py:387]            ^^^^^^^^^^^^^^^^^^^^^
ERROR 05-07 02:15:58 [core.py:387] torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 47.53 GiB of which 14.12 MiB is free. Process 218104 has 260.00 MiB memory in use. Process 218770 has 38.29 GiB memory in use. Including non-PyTorch memory, this process has 8.95 GiB memory in use. Of the allocated memory 8.64 GiB is allocated by PyTorch, and 19.68 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
ERROR 05-07 02:15:58 [core.py:387] 
CRITICAL 05-07 02:15:58 [core_client.py:359] Got fatal signal from worker processes, shutting down. See stack trace above for root cause issue.
