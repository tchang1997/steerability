probe: "./data/steerbench_v2.1.csv"
prompt_strategy: "direct"
llm_settings:
    llm_name: "o3-mini-2025-01-31"
    chat_type: "openai"
    cache_file: "o3_oai.tsv"
    other_kwargs:
        max_simul_calls: 8
        timeout: 3600        
        max_tokens: 4096 # same as main probe
experiment_name: "v2/steerbench_v2.1_o3_mini_2025_01_31" 
seed: 42
inst_addons:
  disambig: True
