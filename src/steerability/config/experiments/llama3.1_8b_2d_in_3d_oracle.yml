probe: "./training_probes/steerability_2d_in_3d_64x16_double_trouble_ipo_beta_train.csv" # yes, probe is incorrectly named
prompt_strategy: "direct"
llm_settings:
    llm_name: "meta-llama/Meta-Llama-3.1-8B-Instruct"
    chat_type: "vllm"
    cache_file: "vllm-meta-llama3-8b.tsv"
    other_kwargs:
        port: 16384 
        max_simul_calls: 4 # 256 concurrent is the max we seem to be able to handle (max_simul_calls * num_generations)
        timeout: 6000 # WHAT THE
        text_gen_kwargs: # in sammo-language
            randomness: 1.0
            num_generations: 256
            min_p: 0.2
            frequency_penalty: 0.1
inst_addons:
    disambig: True
experiment_name: "llama3.1_8b_2d_in_3d_train_best_of_256"
seed: 42
